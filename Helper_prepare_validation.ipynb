{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-18T12:23:36.519850Z",
     "start_time": "2018-12-18T12:23:33.447638Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['submissions', 'test_set', 'track_features', 'training_set']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "import keggler as kg\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "import gc\n",
    "gc.enable()\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "import os, psutil\n",
    "\n",
    "# Set up a logger to dump messages to both log file and notebook\n",
    "import logging as logging\n",
    "def ini_log(filename):\n",
    "    logger = logging.getLogger(__name__)\n",
    "    ## avoid multiple printouts due to same handlers added several times\n",
    "    if not logger.handlers:\n",
    "        logger.setLevel(logging.DEBUG)\n",
    "\n",
    "        handlers = [#logging.StreamHandler(None), \n",
    "            logging.FileHandler(filename, 'a')\n",
    "        ]\n",
    "\n",
    "        fmt=logging.Formatter('%(asctime)-15s: %(levelname)s  %(message)s')\n",
    "        for h in handlers:\n",
    "            h.setFormatter(fmt)\n",
    "            logger.addHandler(h)\n",
    "    return logger\n",
    "        \n",
    "log = ini_log('out.log')\n",
    "\n",
    "#PATH='data_mini/'\n",
    "#prefix='_mini'\n",
    "\n",
    "PATH='data/'\n",
    "prefix=''\n",
    "\n",
    "print(os.listdir(PATH))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T11:03:14.866890Z",
     "start_time": "2018-12-17T11:03:14.861479Z"
    }
   },
   "source": [
    "# Read in track features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-18T12:26:31.781862Z",
     "start_time": "2018-12-18T12:26:31.778473Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = 'data/' # point this to your data folder\n",
    "trn_path = data_path + '/training_set/'\n",
    "# submission_path = data_path + 'submissions/'\n",
    "# val_input_logs = sorted(glob.glob(test_path + \"log_input_*.csv.gz\"))\n",
    "# val_prehi_logs = sorted(glob.glob(test_path + \"log_prehistory_*.csv.gz\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-17T11:53:39.360659Z",
     "start_time": "2018-12-17T11:53:39.355981Z"
    }
   },
   "source": [
    "# Merge DS with Track features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-18T16:26:45.056574Z",
     "start_time": "2018-12-18T16:26:45.051258Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_data(fin_, path_):\n",
    "    df_trn = pd.read_csv(path_ + '/' + fin_,\n",
    "#                          usecols=[i for i in range(21) if i != 16]\n",
    "                        )\n",
    "    is_first_half = (df_trn['session_position'] <= 0.5*df_trn['session_length'])\n",
    "    df_trn[is_first_half].to_csv(path_ + '/X_' + fin_, index=False, float_format='%.5f', compression='gzip')\n",
    "    df_trn[~is_first_half].to_csv(path_ + '/y_' + fin_, index=False, float_format='%.5f', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-18T12:26:42.562071Z",
     "start_time": "2018-12-18T12:26:42.558056Z"
    }
   },
   "outputs": [],
   "source": [
    "file_list = [c \n",
    "             for c in os.listdir(trn_path) \n",
    "             if c.startswith('valDD')\n",
    "             #and not os.path.isfile(PATH+'training_set/'+'out_'+c)\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-18T12:26:43.791326Z",
     "start_time": "2018-12-18T12:26:43.786676Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['valDD_65.csv.gz']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-18T16:29:24.416517Z",
     "start_time": "2018-12-18T16:26:48.786184Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:35<00:00, 155.63s/it]\n"
     ]
    }
   ],
   "source": [
    "for f in tqdm(file_list):\n",
    "    #['log_0_20180715_000000000000.csv.gz', 'log_0_20180716_000000000000.csv.gz']\n",
    "    preprocess_data(f, trn_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
